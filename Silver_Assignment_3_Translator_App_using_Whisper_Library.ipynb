{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quantumhome/DataAnalysisCaseStudy/blob/master/Silver_Assignment_3_Translator_App_using_Whisper_Library.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Assignment 3 craeate a traslator app which takes your voice/speech as an input(in the language you have selected, give 5 lanuagge choices)\n",
        "convert it to the language you selected as output(in the output also give 5 language**"
      ],
      "metadata": {
        "id": "Sv-FtefSK_-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper googletrans==4.0.0-rc1 gTTS\n",
        "!apt-get install -y ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2Gl0u-MLH9B",
        "outputId": "e202070d-f72d-4407-aa7e-18d810ac56f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.12/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.12/dist-packages (2.5.4)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.12/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.11.12)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.12/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.12/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.12/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.12/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.5.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gTTS) (2.32.4)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.12/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TDi14Oz7ZNC",
        "outputId": "a900b3b6-d805-47bf-adcf-6d3bd09a9147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- NEW TRANSLATION ---\n",
            "1. Select Input Language (1. English, 2. Marathi, 3. Kannada, 4. Punjabi, 5. Hindi):\n",
            "Choice (or 'q' to quit): 4\n",
            "2. Select Output Language (Target):\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "from googletrans import Translator\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import torch\n",
        "import asyncio\n",
        "from IPython.display import Audio, display, Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "# --- COLAB MICROPHONE HELPER ---\n",
        "RECORD_JS = \"\"\"\n",
        "const sleep = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = b => new Promise(resolve => {\n",
        "  const r = new FileReader()\n",
        "  r.onloadend = e => resolve(e.srcElement.result)\n",
        "  r.readAsDataURL(b)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record_audio(filename=\"mic_input.wav\", seconds=5):\n",
        "    print(f\" Recording for {seconds} seconds...\")\n",
        "    display(Javascript(RECORD_JS))\n",
        "    s = output.eval_js('record(%d)' % (seconds * 1000))\n",
        "    b = b64decode(s.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(b)\n",
        "    print(\"Recording finished.\")\n",
        "    return filename\n",
        "\n",
        "# --- WHISPER & TRANSLATION LOGIC ---\n",
        "\n",
        "def get_whisper_transcription(audio_path, language_code=None):\n",
        "    # Detect if a GPU (CUDA) is available\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    use_fp16 = True if device == \"cuda\" else False\n",
        "\n",
        "    print(f\" Loading Whisper model (Base) on {device.upper()}...\")\n",
        "    model = whisper.load_model(\"base\", device=device)\n",
        "\n",
        "    print(f\" Analyzing audio...\")\n",
        "    # Passing fp16=False when on CPU removes the warning\n",
        "    result = model.transcribe(audio_path, language=language_code, fp16=use_fp16)\n",
        "\n",
        "    text = result['text'].strip()\n",
        "    print(f\"Recognized: {text}\")\n",
        "    return text\n",
        "\n",
        "def translate_text(text, dest_language):\n",
        "    \"\"\"Removed 'await' as googletrans 4.0.0rc1 is synchronous\"\"\"\n",
        "    translator = Translator()\n",
        "    try:\n",
        "        # Do not use await here\n",
        "        translated = translator.translate(text, dest=dest_language)\n",
        "        print(f\" Translated ({dest_language}): {translated.text}\")\n",
        "        return translated.text\n",
        "    except Exception as e:\n",
        "        print(f\" Translation error: {e}\")\n",
        "        return None\n",
        "\n",
        "def text_to_speech(text, language_code):\n",
        "    if not text: return\n",
        "    tts = gTTS(text=text, lang=language_code)\n",
        "    filename = \"translated_audio.mp3\"\n",
        "    tts.save(filename)\n",
        "    display(Audio(filename, autoplay=True))\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "\n",
        "language_options = {\n",
        "    '1': ('English', 'en'),\n",
        "    '2': ('Marathi', 'mr'),\n",
        "    '3': ('Kannada', 'kn'),\n",
        "    '4': ('Punjabi', 'pa'),\n",
        "    '5': ('Hindi', 'hi')\n",
        "}\n",
        "\n",
        "async def main():\n",
        "    while True:\n",
        "        print(\"\\n--- NEW TRANSLATION ---\")\n",
        "        print(\"1. Select Input Language (1. English, 2. Marathi, 3. Kannada, 4. Punjabi, 5. Hindi):\")\n",
        "        in_choice = input(\"Choice (or 'q' to quit): \")\n",
        "        if in_choice.lower() == 'q': break\n",
        "        in_lang = language_options.get(in_choice, ('English', 'en'))[1]\n",
        "\n",
        "        print(\"2. Select Output Language (Target):\")\n",
        "        out_lang = language_options.get(input(\"Choice: \"), ('Marathi', 'mr'))[1]\n",
        "\n",
        "        print(\"\\n3. Choose Source:\\n(1) Microphone\\n(2) Uploaded MP3 File\")\n",
        "        source_choice = input(\"Choice: \")\n",
        "\n",
        "        audio_path = \"\"\n",
        "        if source_choice == '1':\n",
        "            duration = int(input(\"How many seconds to record? \") or 5)\n",
        "            audio_path = record_audio(seconds=duration)\n",
        "        else:\n",
        "            audio_path = \"/content/sample_data/AnimalSongSearch.mp3\"\n",
        "            if not os.path.exists(audio_path):\n",
        "                print(f\"File not found at {audio_path}. Please upload it to Colab.\")\n",
        "                continue\n",
        "\n",
        "        # 1. Transcribe (Speech to Text)\n",
        "        text = get_whisper_transcription(audio_path, language_code=in_lang)\n",
        "\n",
        "        if text:\n",
        "            # 2. Translate (Text to Text) - No await needed\n",
        "            translated_text = translate_text(text, out_lang)\n",
        "\n",
        "            # 3. Speak (Text to Speech)\n",
        "            if translated_text:\n",
        "                text_to_speech(translated_text, out_lang)\n",
        "\n",
        "        input(\"\\nPress Enter to start another translation...\")\n",
        "\n",
        "# Run the app\n",
        "await main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyN/RwNLqzeplh+L3MDfveh+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}